{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\python311\\lib\\site-packages (10.0.1)\n",
      "Requirement already satisfied: opencv-python in c:\\python311\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.25.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.5.2)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2023.5.7)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.7/385.0 MB 25.9 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.7/385.0 MB 24.1 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 13.6/385.0 MB 23.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 17.0/385.0 MB 21.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 20.4/385.0 MB 19.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 23.9/385.0 MB 19.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 27.3/385.0 MB 18.8 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 30.9/385.0 MB 18.7 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 36.2/385.0 MB 19.5 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 41.2/385.0 MB 20.0 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 45.6/385.0 MB 20.2 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 50.1/385.0 MB 20.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 54.8/385.0 MB 20.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 59.8/385.0 MB 20.8 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 65.3/385.0 MB 21.2 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 70.5/385.0 MB 21.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 76.0/385.0 MB 21.8 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 81.0/385.0 MB 21.9 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 86.8/385.0 MB 22.2 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 92.3/385.0 MB 22.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 98.0/385.0 MB 22.8 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 104.1/385.0 MB 23.1 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 110.9/385.0 MB 23.4 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 117.2/385.0 MB 23.8 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 123.7/385.0 MB 24.1 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 130.3/385.0 MB 24.3 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 136.6/385.0 MB 24.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 142.3/385.0 MB 24.6 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 149.7/385.0 MB 25.0 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 156.5/385.0 MB 25.2 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 159.9/385.0 MB 24.9 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 164.6/385.0 MB 24.9 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 170.1/385.0 MB 24.9 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 175.9/385.0 MB 25.0 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 183.2/385.0 MB 25.3 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 190.3/385.0 MB 25.6 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 196.6/385.0 MB 25.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 203.4/385.0 MB 25.8 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 210.8/385.0 MB 26.1 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 218.6/385.0 MB 26.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 226.8/385.0 MB 26.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 234.4/385.0 MB 26.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 241.7/385.0 MB 27.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 247.5/385.0 MB 27.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 252.7/385.0 MB 27.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 258.7/385.0 MB 27.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 264.8/385.0 MB 27.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 270.0/385.0 MB 27.3 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 276.8/385.0 MB 27.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 284.2/385.0 MB 28.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 290.2/385.0 MB 28.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 297.8/385.0 MB 29.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 304.6/385.0 MB 29.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 310.9/385.0 MB 29.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 317.2/385.0 MB 30.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 323.5/385.0 MB 30.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 328.2/385.0 MB 30.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 333.7/385.0 MB 30.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 341.3/385.0 MB 30.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 347.6/385.0 MB 30.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.9/385.0 MB 30.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 361.2/385.0 MB 30.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.1/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/385.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.7/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.0/385.0 MB 29.3 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 32.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 28.9 MB/s eta 0:00:00\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 27.6 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 34.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.2/26.4 MB 34.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.8/26.4 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 32.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 5.0/5.5 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 23.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Installing collected packages: namex, libclang, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python311\\\\Scripts\\\\markdown_py.exe' -> 'C:\\\\Python311\\\\Scripts\\\\markdown_py.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow opencv-python numpy tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop and resize images\n",
    "\n",
    "The images are 3552x3552 pixels and contain a lot of empty space at the edges. Here we crop the images to 2048x2048 toward the center. Then they are resized to 64x64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.\\\\data\\\\raw_data\\\\0', '.\\\\data\\\\processed_64\\\\0'),\n",
      " ('.\\\\data\\\\raw_data\\\\1', '.\\\\data\\\\processed_64\\\\1'),\n",
      " ('.\\\\data\\\\raw_data\\\\2', '.\\\\data\\\\processed_64\\\\2'),\n",
      " ('.\\\\data\\\\raw_data\\\\3', '.\\\\data\\\\processed_64\\\\3'),\n",
      " ('.\\\\data\\\\raw_data\\\\4', '.\\\\data\\\\processed_64\\\\4'),\n",
      " ('.\\\\data\\\\raw_data\\\\5', '.\\\\data\\\\processed_64\\\\5'),\n",
      " ('.\\\\data\\\\raw_data\\\\6', '.\\\\data\\\\processed_64\\\\6'),\n",
      " ('.\\\\data\\\\raw_data\\\\7', '.\\\\data\\\\processed_64\\\\7'),\n",
      " ('.\\\\data\\\\raw_data\\\\8', '.\\\\data\\\\processed_64\\\\8'),\n",
      " ('.\\\\data\\\\raw_data\\\\9', '.\\\\data\\\\processed_64\\\\9'),\n",
      " ('.\\\\data\\\\raw_data\\\\10', '.\\\\data\\\\processed_64\\\\10'),\n",
      " ('.\\\\data\\\\raw_data\\\\11', '.\\\\data\\\\processed_64\\\\11'),\n",
      " ('.\\\\data\\\\raw_data\\\\12', '.\\\\data\\\\processed_64\\\\12'),\n",
      " ('.\\\\data\\\\raw_data\\\\13', '.\\\\data\\\\processed_64\\\\13'),\n",
      " ('.\\\\data\\\\raw_data\\\\14', '.\\\\data\\\\processed_64\\\\14'),\n",
      " ('.\\\\data\\\\raw_data\\\\15', '.\\\\data\\\\processed_64\\\\15')]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "dirs = [ (f'.\\\\data\\\\raw_data\\\\{num}', f'.\\\\data\\\\processed_64\\\\{num}') for num in range(16) ]\n",
    "# dirs = [(\"./data/sanity_check_raw\", \"./data/sanity_check\")]\n",
    "\n",
    "pprint(dirs)\n",
    "for (in_dir, out_dir) in dirs:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "original_size = 3552\n",
    "crop_size = 2048\n",
    "target_size = 64\n",
    "max_files = 60 # We want the same number of images of each ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing .\\data\\raw_data\\0 ...\n",
      "Processing .\\data\\raw_data\\1 ...\n",
      "Processing .\\data\\raw_data\\2 ...\n",
      "Processing .\\data\\raw_data\\3 ...\n",
      "Processing .\\data\\raw_data\\4 ...\n",
      "Processing .\\data\\raw_data\\5 ...\n",
      "Processing .\\data\\raw_data\\6 ...\n",
      "Processing .\\data\\raw_data\\7 ...\n",
      "Processing .\\data\\raw_data\\8 ...\n",
      "Processing .\\data\\raw_data\\9 ...\n",
      "Processing .\\data\\raw_data\\10 ...\n",
      "Processing .\\data\\raw_data\\11 ...\n",
      "Processing .\\data\\raw_data\\12 ...\n",
      "Processing .\\data\\raw_data\\13 ...\n",
      "Processing .\\data\\raw_data\\14 ...\n",
      "Processing .\\data\\raw_data\\15 ...\n"
     ]
    }
   ],
   "source": [
    "left = (original_size - crop_size) // 2\n",
    "top = (original_size - crop_size) // 2\n",
    "right = (original_size + crop_size) // 2\n",
    "bottom = (original_size + crop_size) // 2\n",
    "\n",
    "# Values for phone pictures\n",
    "# top = 200\n",
    "# left = 360\n",
    "# bottom = 760\n",
    "# right = 820\n",
    "\n",
    "for (in_dir, out_dir) in dirs:\n",
    "    files = os.listdir(in_dir)\n",
    "    print(f\"Processing {in_dir} ...\")\n",
    "\n",
    "    counter = 0\n",
    "    for filename in files[:max_files]:\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            counter += 1\n",
    "            # Open the image\n",
    "            img_path = os.path.join(in_dir, filename)\n",
    "            output_path = os.path.join(out_dir, filename)\n",
    "            \n",
    "            Image.open(img_path\n",
    "                ).crop((left, top, right, bottom)\n",
    "                ).resize((target_size, target_size), Image.Resampling.LANCZOS\n",
    "                ).save(output_path)\n",
    "\n",
    "            # print(f\"Cropped and saved: {output_path} ({counter} of {max_files})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training, validation and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 files belonging to 16 classes.\n",
      "Splitting data into training, validation and testing datasets...\n",
      "X_train (720, 64, 64, 3)\n",
      "y_train (720,)\n",
      "X_val (80, 64, 64, 3)\n",
      "y_val (80,)\n",
      "X_test (160, 64, 64, 3)\n",
      "y_test (160,)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = './data/processed_64'\n",
    "batch_size = 25\n",
    "img_width = 64\n",
    "img_height = 64\n",
    "\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "class_names = dataset.class_names # ['0', '1', '10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "image_batches = []\n",
    "label_batches = []\n",
    "\n",
    "for images, labels in dataset:\n",
    "    image_batches.append(images)\n",
    "    label_batches.append(labels)\n",
    "\n",
    "X = np.concatenate(image_batches)\n",
    "y = np.concatenate(label_batches)\n",
    "\n",
    "print(\"Splitting data into training, validation and testing datasets...\")\n",
    "\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size = (2/3), random_state = 0)\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_val\", X_val.shape)\n",
    "print(\"y_val\", y_val.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "normalization_layer = keras.layers.Rescaling(1./255) # Rescale RGB values from 0..255 to floats in 0..1\n",
    "\n",
    "augmentation_layer = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomBrightness(0.05)\n",
    "])\n",
    "\n",
    "batch_size = 50\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (augmentation_layer(x), y)).map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    "    ).shuffle(buffer_size=len(X_train), seed=0, reshuffle_each_iteration=True\n",
    "    ).batch(batch_size\n",
    "    ).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    "    ).batch(batch_size\n",
    "    ).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    "    ).batch(batch_size\n",
    "    ).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "model = keras.Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0568 - loss: 2.7882 - val_accuracy: 0.1125 - val_loss: 2.7291\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1529 - loss: 2.6524 - val_accuracy: 0.2375 - val_loss: 2.2633\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2825 - loss: 2.1051 - val_accuracy: 0.5125 - val_loss: 1.4607\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5283 - loss: 1.4026 - val_accuracy: 0.7250 - val_loss: 0.9527\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6053 - loss: 1.1428 - val_accuracy: 0.8000 - val_loss: 0.7184\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7302 - loss: 0.7818 - val_accuracy: 0.6250 - val_loss: 0.8014\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7148 - loss: 0.6968 - val_accuracy: 0.8000 - val_loss: 0.4975\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8030 - loss: 0.5265 - val_accuracy: 0.8750 - val_loss: 0.4825\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8597 - loss: 0.4229 - val_accuracy: 0.8000 - val_loss: 0.4776\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8462 - loss: 0.4159 - val_accuracy: 0.8625 - val_loss: 0.3562\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8919 - loss: 0.2975 - val_accuracy: 0.8750 - val_loss: 0.3431\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8977 - loss: 0.2810 - val_accuracy: 0.8500 - val_loss: 0.2855\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9313 - loss: 0.2250 - val_accuracy: 0.9000 - val_loss: 0.2565\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9175 - loss: 0.2177 - val_accuracy: 0.9250 - val_loss: 0.2299\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9212 - loss: 0.2013 - val_accuracy: 0.9000 - val_loss: 0.2767\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9468 - loss: 0.1521 - val_accuracy: 0.9375 - val_loss: 0.1615\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9588 - loss: 0.1576 - val_accuracy: 0.9125 - val_loss: 0.2305\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9314 - loss: 0.1955 - val_accuracy: 0.9750 - val_loss: 0.1362\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9605 - loss: 0.1280 - val_accuracy: 0.9250 - val_loss: 0.1918\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9557 - loss: 0.1326 - val_accuracy: 0.9375 - val_loss: 0.1441\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9639 - loss: 0.1035 - val_accuracy: 0.9375 - val_loss: 0.1434\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9469 - loss: 0.1279 - val_accuracy: 0.9375 - val_loss: 0.1403\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9504 - loss: 0.1346 - val_accuracy: 0.9375 - val_loss: 0.1866\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9408 - loss: 0.1683 - val_accuracy: 0.9500 - val_loss: 0.1254\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9614 - loss: 0.1060 - val_accuracy: 0.9750 - val_loss: 0.1085\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9920 - loss: 0.0688 - val_accuracy: 0.9500 - val_loss: 0.1607\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9739 - loss: 0.0767 - val_accuracy: 0.9625 - val_loss: 0.1817\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9812 - loss: 0.0614 - val_accuracy: 0.9625 - val_loss: 0.1159\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9732 - loss: 0.0783 - val_accuracy: 0.9500 - val_loss: 0.1705\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9708 - loss: 0.0819 - val_accuracy: 0.9000 - val_loss: 0.1968\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.1005 - val_accuracy: 0.9750 - val_loss: 0.1337\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9702 - loss: 0.0740 - val_accuracy: 0.9625 - val_loss: 0.1438\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9840 - loss: 0.0693 - val_accuracy: 0.9750 - val_loss: 0.1115\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9673 - loss: 0.0747 - val_accuracy: 0.9750 - val_loss: 0.1123\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9809 - loss: 0.0653 - val_accuracy: 0.9500 - val_loss: 0.1358\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9789 - loss: 0.0746 - val_accuracy: 0.9375 - val_loss: 0.2359\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9584 - loss: 0.1020 - val_accuracy: 0.8750 - val_loss: 0.4129\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9696 - loss: 0.1055 - val_accuracy: 0.9375 - val_loss: 0.1665\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9750 - loss: 0.0683 - val_accuracy: 0.9500 - val_loss: 0.1226\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9833 - loss: 0.0516 - val_accuracy: 0.9625 - val_loss: 0.0956\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9903 - loss: 0.0422 - val_accuracy: 0.9625 - val_loss: 0.1120\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9647 - loss: 0.0910 - val_accuracy: 0.9750 - val_loss: 0.0769\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9730 - loss: 0.0751 - val_accuracy: 0.9750 - val_loss: 0.1222\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9806 - loss: 0.0453 - val_accuracy: 0.9750 - val_loss: 0.0681\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9877 - loss: 0.0417 - val_accuracy: 0.9750 - val_loss: 0.0973\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9916 - loss: 0.0318 - val_accuracy: 0.9750 - val_loss: 0.1036\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9926 - loss: 0.0352 - val_accuracy: 0.9750 - val_loss: 0.0633\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9867 - loss: 0.0313 - val_accuracy: 0.9875 - val_loss: 0.0384\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9886 - loss: 0.0268 - val_accuracy: 0.9750 - val_loss: 0.0702\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9896 - loss: 0.0292 - val_accuracy: 0.9750 - val_loss: 0.0893\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0721 \n",
      "Loss:  0.06632108986377716 \n",
      " Accuracy:  0.9750000238418579\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(\"Loss: \", loss, \"\\n\", \"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "This image most likely belongs to 14 with a 100.00 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "image = keras.utils.load_img(\".\\\\data\\\\sanity_check\\\\14.JPG\")\n",
    "\n",
    "image_array = keras.utils.img_to_array(image)\n",
    "image_array = tf.expand_dims(image_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(image_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
