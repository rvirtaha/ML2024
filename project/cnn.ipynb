{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\python311\\lib\\site-packages (10.0.1)\n",
      "Requirement already satisfied: opencv-python in c:\\python311\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.25.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.5.2)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2023.5.7)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rvirt\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.7/385.0 MB 25.9 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.7/385.0 MB 24.1 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 13.6/385.0 MB 23.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 17.0/385.0 MB 21.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 20.4/385.0 MB 19.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 23.9/385.0 MB 19.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 27.3/385.0 MB 18.8 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 30.9/385.0 MB 18.7 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 36.2/385.0 MB 19.5 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 41.2/385.0 MB 20.0 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 45.6/385.0 MB 20.2 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 50.1/385.0 MB 20.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 54.8/385.0 MB 20.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 59.8/385.0 MB 20.8 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 65.3/385.0 MB 21.2 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 70.5/385.0 MB 21.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 76.0/385.0 MB 21.8 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 81.0/385.0 MB 21.9 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 86.8/385.0 MB 22.2 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 92.3/385.0 MB 22.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 98.0/385.0 MB 22.8 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 104.1/385.0 MB 23.1 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 110.9/385.0 MB 23.4 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 117.2/385.0 MB 23.8 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 123.7/385.0 MB 24.1 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 130.3/385.0 MB 24.3 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 136.6/385.0 MB 24.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 142.3/385.0 MB 24.6 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 149.7/385.0 MB 25.0 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 156.5/385.0 MB 25.2 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 159.9/385.0 MB 24.9 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 164.6/385.0 MB 24.9 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 170.1/385.0 MB 24.9 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 175.9/385.0 MB 25.0 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 183.2/385.0 MB 25.3 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 190.3/385.0 MB 25.6 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 196.6/385.0 MB 25.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 203.4/385.0 MB 25.8 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 210.8/385.0 MB 26.1 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 218.6/385.0 MB 26.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 226.8/385.0 MB 26.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 234.4/385.0 MB 26.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 241.7/385.0 MB 27.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 247.5/385.0 MB 27.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 252.7/385.0 MB 27.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 258.7/385.0 MB 27.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 264.8/385.0 MB 27.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 270.0/385.0 MB 27.3 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 276.8/385.0 MB 27.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 284.2/385.0 MB 28.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 290.2/385.0 MB 28.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 297.8/385.0 MB 29.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 304.6/385.0 MB 29.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 310.9/385.0 MB 29.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 317.2/385.0 MB 30.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 323.5/385.0 MB 30.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 328.2/385.0 MB 30.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 333.7/385.0 MB 30.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 341.3/385.0 MB 30.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 347.6/385.0 MB 30.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.9/385.0 MB 30.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 361.2/385.0 MB 30.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.1/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/385.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.7/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 31.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.0/385.0 MB 29.3 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 32.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 28.9 MB/s eta 0:00:00\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 27.6 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 34.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.2/26.4 MB 34.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.8/26.4 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 32.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 5.0/5.5 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 23.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Installing collected packages: namex, libclang, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python311\\\\Scripts\\\\markdown_py.exe' -> 'C:\\\\Python311\\\\Scripts\\\\markdown_py.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow opencv-python numpy tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop and resize images\n",
    "\n",
    "The images are 3552x3552 pixels and contain a lot of empty space at the edges. Here we crop the images to 2048x2048 toward the center. Then they are resized to 64x64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./data/sanity_check_raw', './data/sanity_check')]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "dirs = [ (f'.\\\\data\\\\raw_data\\\\{num}', f'.\\\\data\\\\processed_64\\\\{num}') for num in range(16) ]\n",
    "# dirs = [(\"./data/sanity_check_raw\", \"./data/sanity_check\")]\n",
    "\n",
    "pprint(dirs)\n",
    "for (in_dir, out_dir) in dirs:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "original_size = 3552\n",
    "crop_size = 2048\n",
    "target_size = 64\n",
    "max_files = 60 # We want the same number of images of each ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./data/sanity_check_raw ...\n"
     ]
    }
   ],
   "source": [
    "left = (original_size - crop_size) // 2\n",
    "top = (original_size - crop_size) // 2\n",
    "right = (original_size + crop_size) // 2\n",
    "bottom = (original_size + crop_size) // 2\n",
    "\n",
    "# Values for phone pictures\n",
    "# top = 200\n",
    "# left = 360\n",
    "# bottom = 760\n",
    "# right = 820\n",
    "\n",
    "for (in_dir, out_dir) in dirs:\n",
    "    files = os.listdir(in_dir)\n",
    "    print(f\"Processing {in_dir} ...\")\n",
    "\n",
    "    counter = 0\n",
    "    for filename in files[:max_files]:\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            counter += 1\n",
    "            # Open the image\n",
    "            img_path = os.path.join(in_dir, filename)\n",
    "            output_path = os.path.join(out_dir, filename)\n",
    "            \n",
    "            Image.open(img_path\n",
    "                ).crop((left, top, right, bottom)\n",
    "                ).resize((target_size, target_size), Image.Resampling.LANCZOS\n",
    "                ).save(output_path)\n",
    "\n",
    "            # print(f\"Cropped and saved: {output_path} ({counter} of {max_files})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a test split randomly from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "random.seed(0)\n",
    "data_dir = pathlib.Path('./data/processed_64').with_suffix('')\n",
    "# Access the data like so: \n",
    "#   ball8 = list(data_dir.glob(('8/*.jpg')))\n",
    "#   Image.open(str(ball8[0]))\n",
    "\n",
    "# Take a test data split\n",
    "test_items_per_category = 10\n",
    "\n",
    "for dir in os.listdir('./data/processed_64'):\n",
    "    image_paths = list(data_dir.glob(f'{dir}/*.jpg'))\n",
    "    test_split = random.sample(image_paths, test_items_per_category)\n",
    "    rest_split = [ item for item in image_paths if item not in test_split]\n",
    "    \n",
    "    test_dir = f'./data/test/{dir}'\n",
    "    rest_dir = f'./data/train_and_validation/{dir}'\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    os.makedirs(rest_dir, exist_ok=True)\n",
    "\n",
    "    for path in test_split:\n",
    "        shutil.move(path, test_dir)\n",
    "    for path in rest_split:\n",
    "        shutil.move(path, rest_dir)\n",
    "\n",
    "shutil.rmtree('./data/processed_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 files belonging to 16 classes.\n",
      "Using 720 files for training.\n",
      "Using 80 files for validation.\n",
      "Found 160 files belonging to 16 classes.\n",
      "['0', '1', '10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "batch_size = 25\n",
    "img_width = 64\n",
    "img_height = 64\n",
    "\n",
    "data_dir = pathlib.Path('./data/train_and_validation').with_suffix('')\n",
    "test_dir = pathlib.Path('./data/test').with_suffix('')\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "normalization_layer = keras.layers.Rescaling(1./255) # Rescale RGB values from 0..255 to floats in 0..1\n",
    "\n",
    "data_aug = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomBrightness(0.1)\n",
    "])\n",
    "\n",
    "batch_size = 30\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    \n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (data_aug(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_ds = prepare(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "model = keras.Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.0997 - loss: 15.4631 - val_accuracy: 0.2500 - val_loss: 2.5651\n",
      "Epoch 2/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2324 - loss: 2.3965 - val_accuracy: 0.5250 - val_loss: 1.1906\n",
      "Epoch 3/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5362 - loss: 1.3623 - val_accuracy: 0.5875 - val_loss: 1.2517\n",
      "Epoch 4/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6787 - loss: 0.9481 - val_accuracy: 0.8250 - val_loss: 0.5721\n",
      "Epoch 5/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7029 - loss: 0.8156 - val_accuracy: 0.7000 - val_loss: 1.0519\n",
      "Epoch 6/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7258 - loss: 0.7319 - val_accuracy: 0.8125 - val_loss: 0.4855\n",
      "Epoch 7/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8294 - loss: 0.5036 - val_accuracy: 0.8125 - val_loss: 0.4658\n",
      "Epoch 8/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8270 - loss: 0.4578 - val_accuracy: 0.8125 - val_loss: 0.4240\n",
      "Epoch 9/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8671 - loss: 0.3473 - val_accuracy: 0.8125 - val_loss: 0.4157\n",
      "Epoch 10/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8235 - loss: 0.4161 - val_accuracy: 0.8625 - val_loss: 0.3363\n",
      "Epoch 11/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8843 - loss: 0.3372 - val_accuracy: 0.9000 - val_loss: 0.2216\n",
      "Epoch 12/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9259 - loss: 0.2579 - val_accuracy: 0.8750 - val_loss: 0.3080\n",
      "Epoch 13/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8909 - loss: 0.3041 - val_accuracy: 0.9250 - val_loss: 0.1973\n",
      "Epoch 14/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9044 - loss: 0.3030 - val_accuracy: 0.9250 - val_loss: 0.2071\n",
      "Epoch 15/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9146 - loss: 0.2397 - val_accuracy: 0.8000 - val_loss: 0.6034\n",
      "Epoch 16/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9120 - loss: 0.2710 - val_accuracy: 0.9125 - val_loss: 0.1526\n",
      "Epoch 17/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9542 - loss: 0.1483 - val_accuracy: 0.9250 - val_loss: 0.1466\n",
      "Epoch 18/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9320 - loss: 0.2098 - val_accuracy: 0.9250 - val_loss: 0.2400\n",
      "Epoch 19/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9223 - loss: 0.2202 - val_accuracy: 0.9375 - val_loss: 0.2435\n",
      "Epoch 20/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9384 - loss: 0.1633 - val_accuracy: 0.9625 - val_loss: 0.0982\n",
      "Epoch 21/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9575 - loss: 0.1291 - val_accuracy: 0.9250 - val_loss: 0.2608\n",
      "Epoch 22/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9234 - loss: 0.2277 - val_accuracy: 0.9500 - val_loss: 0.1106\n",
      "Epoch 23/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9602 - loss: 0.1362 - val_accuracy: 0.9875 - val_loss: 0.0837\n",
      "Epoch 24/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9378 - loss: 0.1612 - val_accuracy: 0.9375 - val_loss: 0.1969\n",
      "Epoch 25/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9204 - loss: 0.1785 - val_accuracy: 0.9125 - val_loss: 0.3978\n",
      "Epoch 26/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9241 - loss: 0.2258 - val_accuracy: 0.9500 - val_loss: 0.0872\n",
      "Epoch 27/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9663 - loss: 0.1062 - val_accuracy: 0.9375 - val_loss: 0.1663\n",
      "Epoch 28/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9286 - loss: 0.2039 - val_accuracy: 0.9500 - val_loss: 0.1018\n",
      "Epoch 29/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9561 - loss: 0.1462 - val_accuracy: 0.8875 - val_loss: 0.3112\n",
      "Epoch 30/30\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9592 - loss: 0.1453 - val_accuracy: 0.9750 - val_loss: 0.1509\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9476 - loss: 0.1727\n",
      "Loss:  0.11524226516485214 \n",
      " Accuracy:  0.9624999761581421\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(\"Loss: \", loss, \"\\n\", \"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "This image most likely belongs to 14 with a 91.89 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "image = keras.utils.load_img(\".\\\\data\\\\sanity_check\\\\14.JPG\")\n",
    "\n",
    "image_array = keras.utils.img_to_array(image)\n",
    "image_array = tf.expand_dims(image_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(image_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
