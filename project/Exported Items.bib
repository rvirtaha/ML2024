@article{bartlettClassificationRejectOption2008,
  title = {Classification with a {{Reject Option}} Using a {{Hinge Loss}}},
  author = {Bartlett, Peter L and Wegkamp, Marten H},
  year = {2008},
  month = aug,
  abstract = {We consider the problem of binary classification where the classifier can, for a particular cost, choose not to classify an observation. Just as in the conventional classification problem, minimization of the sample average of the cost is a difficult optimization problem. As an alternative, we propose the optimization of a certain convex loss function {$\varphi$}, analogous to the hinge loss used in support vector machines (SVMs). Its convexity ensures that the sample average of this surrogate loss can be efficiently minimized. We study its statistical properties. We show that minimizing the expected surrogate loss---the {$\varphi$}-risk---also minimizes the risk. We also study the rate at which the {$\varphi$}-risk approaches its minimum value. We show that fast rates are possible when the conditional probability P(Y = 1{\textbar}X) is unlikely to be close to certain critical values.},
  langid = {english},
  file = {C:\Users\rvirt\Zotero\storage\3IQDW9PL\Bartlett ja Wegkamp - ClassiÔ¨Åcation with a Reject Option using a Hinge Loss.pdf}
}

@article{josephOptimalRatioData2022,
  title = {Optimal {{Ratio}} for {{Data Splitting}}},
  author = {Joseph, V. Roshan},
  year = {2022},
  month = aug,
  journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  volume = {15},
  number = {4},
  eprint = {2202.03326},
  primaryclass = {cs, stat},
  pages = {531--538},
  issn = {1932-1864, 1932-1872},
  doi = {10.1002/sam.11583},
  urldate = {2024-09-19},
  abstract = {It is common to split a dataset into training and testing sets before fitting a statistical or machine learning model. However, there is no clear guidance on how much data should be used for training and testing. In this article we show that the optimal splitting ratio is \${\textbackslash}sqrt\{p\}:1\$, where \$p\$ is the number of parameters in a linear regression model that explains the data well.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\rvirt\\Zotero\\storage\\AMMYGZFT\\Joseph - 2022 - Optimal Ratio for Data Splitting.pdf;C\:\\Users\\rvirt\\Zotero\\storage\\FPDY3D7U\\2202.html}
}

@book{jungMachineLearningBasics2022,
  title = {Machine {{Learning}}: {{The Basics}}},
  shorttitle = {Machine {{Learning}}},
  author = {Jung, Alexander},
  year = {2022},
  series = {Machine {{Learning}}: {{Foundations}}, {{Methodologies}}, and {{Applications}}},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-16-8193-6},
  urldate = {2024-09-20},
  copyright = {https://www.springer.com/tdm},
  isbn = {9789811681929 9789811681936},
  langid = {english},
  file = {C:\Users\rvirt\Zotero\storage\24LREQCK\Jung - 2022 - Machine Learning The Basics.pdf}
}

@article{nobleWhatSupportVector2006,
  title = {What Is a Support Vector Machine?},
  author = {Noble, William S},
  year = {2006},
  month = dec,
  journal = {Nature Biotechnology},
  volume = {24},
  number = {12},
  pages = {1565--1567},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/nbt1206-1565},
  urldate = {2024-09-20},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {C:\Users\rvirt\Zotero\storage\BGSV34YL\Noble - 2006 - What is a support vector machine.pdf}
}

@techreport{unknownMachineLearningApproach2023,
  title = {A {{Machine Learning Approach}} to {{Classifying Bangla Handwritten Characters}}},
  author = {{unknown}},
  year = {2023},
  month = sep,
  file = {C:\Users\rvirt\Zotero\storage\WADLHR9B\Bangla_Handwritten_Character_Classification-S2-1.pdf}
}

@misc{ImportanceFeatureScaling,
  title = {Importance of {{Feature Scaling}}},
  journal = {scikit-learn},
  urldate = {2024-09-20},
  abstract = {Feature scaling through standardization, also called Z-score normalization, is an important preprocessing step for many machine learning algorithms. It involves rescaling each feature such that it ...},
  howpublished = {\url{https://scikit-learn/stable/auto\_examples/preprocessing/plot\_scaling\_importance.html}},
  langid = {english},
  file = {C:\Users\rvirt\Zotero\storage\N9XHW2KI\plot_scaling_importance.html}
}

@misc{ComputerVisionTensorFlow,
  title = {Computer Vision with {{TensorFlow}} {\textbar} {{TensorFlow Core}}},
  urldate = {2024-09-20},
  howpublished = {\url{https://www.tensorflow.org/tutorials/images}},
  langid = {english},
  file = {C:\Users\rvirt\Zotero\storage\6K39LQCM\images.html}
}
